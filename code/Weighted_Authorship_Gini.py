# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wz7ZfFLhEiTEWLj7VXPJrRrcZp6SiJpB
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

file_path = 'BIP_Content.xlsx'
df = pd.read_excel(file_path)

print(f"Dataset shape: {df.shape}")
print("\nFirst 5 rows:")
print(df.head())

print("\nColumn names:")
print(df.columns.tolist())

import pandas as pd
import re

def parse_bip_header(content):
    """Parse BIP header information from content (extract specified fields only)"""
    # Handle escaped newline characters
    if isinstance(content, str):
        content = content.replace('\\n', '\n')
    else:
        content = str(content)

    result = {
        'BIP': None,
        'Title': None,
        'Author': None,
        'Comments-Summary': None,
        'Comments-URI': None,
        'Status': None,
        'Type': None,
        'Created': None,
        'Superseded-By': None
    }

    # For most fields, use single-line matching
    single_line_fields = ['BIP', 'Title', 'Comments-Summary', 'Comments-URI',
                          'Status', 'Type', 'Created', 'Superseded-By']

    for key in single_line_fields:
        pattern = rf'^\s*{re.escape(key)}:\s*(.+?)$'
        match = re.search(pattern, content, re.MULTILINE | re.IGNORECASE)
        if match:
            value = match.group(1).strip()
            # Special handling for Status field: remove parentheses and content after
            if key == 'Status' and '(' in value:
                value = value.split('(')[0].strip()
            result[key] = value

    # Special handling for Author field: support multiple lines
    # Match lines starting with "Author:", then all subsequent indented lines until next field
    author_pattern = r'Author:\s*(.+?)(?=\n\s*[A-Z][a-z\-]+:|$)'
    author_match = re.search(author_pattern, content, re.DOTALL | re.IGNORECASE)

    if author_match:
        author_text = author_match.group(1).strip()
        author_text = re.sub(r'\s+', ' ', author_text)
        result['Author'] = author_text

    return result

parsed_data = df['content'].apply(parse_bip_header)

df_proposal = pd.DataFrame(parsed_data.tolist())

print("First 5 rows of parsed dataset:")
print(df_proposal.head())
print("\nDataset shape:")
print(df_proposal.shape)
print("\nColumn names:")
print(df_proposal.columns.tolist())

# Step 1: Extract individual author list (keep names, remove emails)
def extract_individual_authors(author_str):
    """
    Extract each author's name from the Author string (remove emails)
    Returns a list of author names
    """
    if pd.isna(author_str):
        return []
    authors = re.findall(r'([^<>,]+)\s*<[^>]+>', author_str)
    clean_authors = []
    for author in authors:
        author = author.strip()
        author = re.sub(r'\s+and\s+', ' ', author)
        if author:
            clean_authors.append(author)
    return clean_authors

df_proposal['author_list'] = df_proposal['Author'].apply(extract_individual_authors)


# Step 2: Count number of authors per BIP
df_proposal['author_count'] = df_proposal['author_list'].apply(len)

author_distribution = df_proposal['author_count'].value_counts().sort_index()

print("\nDetailed distribution:")
for count, freq in author_distribution.items():
    if count > 0:
        print(f"{freq} rows have {count} author(s)")
    else:
        print(f"{freq} rows have no author information")

print(df_proposal)

# Author Weighted Contribution Calculation, Gini Coefficient

import pandas as pd
import numpy as np
import re

print("\n【3. Author Analysis - Weighted Contribution】")
print("-" * 60)

# Calculate weighted contribution for each author
# Each author's contribution to a BIP = 1 / number of authors in that BIP
author_weighted_contributions = {}

for idx, row in df_proposal.iterrows():
    author_list = row['author_list']
    author_count = row['author_count']

    if author_count > 0:
        # Each author's contribution to this BIP
        contribution_per_author = 1.0 / author_count

        for author in author_list:
            if author not in author_weighted_contributions:
                author_weighted_contributions[author] = 0
            author_weighted_contributions[author] += contribution_per_author

author_weighted_series = pd.Series(author_weighted_contributions)
author_weighted_series = author_weighted_series.sort_values(ascending=False)

print(f"Total unique authors: {len(author_weighted_series)}")
print(f"Total weighted contribution: {author_weighted_series.sum():.2f} (should equal total BIPs)")

print("\nTop 10 most active authors (by weighted contribution):")
top_authors_weighted = author_weighted_series.head(10)
for author, contribution in top_authors_weighted.items():
    print(f"  {author}: {contribution:.2f}")


# Calculate Gini Coefficient for Weighted Contribution
def calculate_gini(values):
    """
    Calculate Gini coefficient
    Parameters:
        values: Array of values (e.g., number of proposals per author)
    Returns:
        float: Gini coefficient (between 0-1, where 0 = perfect equality, 1 = perfect inequality)
    """
    sorted_values = np.sort(np.array(values))
    n = len(sorted_values)

    cumsum = np.cumsum(sorted_values)

    index = np.arange(1, n + 1)
    gini = (2 * np.sum(index * sorted_values) - (n + 1) * cumsum[-1]) / (n * cumsum[-1])

    return gini

gini_coefficient_weighted = calculate_gini(author_weighted_series.values)
print(f"\nAuthor weighted contribution Gini coefficient: {gini_coefficient_weighted:.4f}")
print(f"  (0 = perfect equality, 1 = perfect inequality)")

# ============================================================================
# Comparison: Simple Count vs Weighted Contribution
# ============================================================================
print("\n" + "="*60)
print("【Comparison Analysis: Simple Count vs Weighted Contribution】")
print("-" * 60)

# Simple count method
all_authors_simple = []
for author_list in df_proposal['author_list']:
    all_authors_simple.extend(author_list)

author_simple_counts = pd.Series(all_authors_simple).value_counts()
gini_coefficient_simple = calculate_gini(author_simple_counts.values)

print(f"Simple count Gini coefficient: {gini_coefficient_simple:.4f}")
print(f"Weighted contribution Gini coefficient: {gini_coefficient_weighted:.4f}")

print("\nExample: Comparison of top 5 authors")
print(f"{'Author':<25} {'Simple Count':<12} {'Weighted':<12} {'Difference':<10}")
print("-" * 60)

top_5_authors = author_weighted_series.head(5).index
for author in top_5_authors:
    simple_count = author_simple_counts.get(author, 0)
    weighted_count = author_weighted_series.get(author, 0)
    diff = weighted_count - simple_count
    print(f"{author:<25} {simple_count:<12} {weighted_count:<12.2f} {diff:<10.2f}")

top_10_contribution_weighted = top_authors_weighted.sum() / author_weighted_series.sum() * 100
print(f"\nTop 10 authors weighted contribution: {top_10_contribution_weighted:.2f}% of total")

output_df = pd.DataFrame({
    'Author': author_weighted_series.index,
    'Weighted_Contribution': author_weighted_series.values,
    'Simple_Count': [author_simple_counts.get(author, 0) for author in author_weighted_series.index]
})

output_df.to_excel('authorship_distribution.xlsx', index=False)